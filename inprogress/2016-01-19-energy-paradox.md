---
layout: post
---

I've been thinking about a puzzling tectonic energy balance question. Two scenarios, both driven by a far field relative plate velocity, $$\Delta u$$:

1. A straight strike slip fault has a long-term average slip-rate equal to $$\Delta u$$.
2. A compressional step over. For kinematic consistency, the slip-rate on the strike-slip segments is still $$\Delta u$$. The horizontal shortening on the thrust must be equal to the slip on the strike-slip segments so it is also equal to $$\Delta u$$.

<img src="/public/images/energy_paradox_fault_systems.png"/>

Kinematically, both these fault systems are perfectly reasonable. Energetically, however, the two fault systems have different energy outputs while having the same energy input. 

The energy entering the system in both cases is the strain energy that accumulates while the faults are locked, a quantity that is only dependent on $$\Delta u$$ and is independent of fault geometry (while faults are locked, from the perspective of elasticity, it is as if they aren't there at all).

However, the energy exiting the system is different between the two cases due to the uplift created by the thrust in scenario 2. In particular, if $$\theta$$ is the dip of the thrust, there is $$ \rho g \Delta u \tan (\theta)$$ of gravitational energy stored in the system per unit volume of uplifted material. The exact volume of uplifted material depends on the dip of the thrust at depth, but lets just call it $V_U$. 

There are connections here with work on plate driving forces. For example, Forsyth and Uyeda (1975) found that slab pull by negatively buoyant subducted ocean crust was the dominant plate driving force. 
